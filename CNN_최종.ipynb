{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlwks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image, ImageFile, ImageOps\n",
    "from torch.utils import data as data_utils\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Histogram_Equalization_pil(image):\n",
    "    r, g, b = image.split()\n",
    "    r_eq = ImageOps.equalize(r)\n",
    "    g_eq = ImageOps.equalize(g)\n",
    "    b_eq = ImageOps.equalize(b)\n",
    "    histogram_image = Image.merge(\"RGB\", (r_eq, g_eq, b_eq))\n",
    "    return np.array(histogram_image)\n",
    "\n",
    "def load_image_pil(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image_pil(path):\n",
    "    image = load_image_pil(path)\n",
    "    image = Histogram_Equalization_pil(image)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(data_path)\n",
    "        self.images = self.load_images()\n",
    "\n",
    "    def load_images(self):\n",
    "        images = []\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(self.data_path, class_name)\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                images.append((image_path, class_name))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, class_name = self.images[index]\n",
    "        image = load_and_preprocess_image_pil(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.classes.index(class_name)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # transforms.Grayscale(),\n",
    "    transforms.RandomRotation(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))  \n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data_path = r'C:\\Users\\dlwks\\OneDrive\\바탕 화면\\VSCode\\BTS_2023\\train'\n",
    "train_dataset = CustomDataset(train_data_path, transform=train_transform)\n",
    "\n",
    "test_data_path = r'C:\\Users\\dlwks\\OneDrive\\바탕 화면\\VSCode\\BTS_2023\\test'\n",
    "test_dataset = CustomDataset(test_data_path, transform=test_transform) \n",
    "\n",
    "image, label = train_dataset[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "## StartifiedShuufleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=val_size, random_state=42)\n",
    "train_indices, val_indices = next(sss.split(train_dataset, [label for _, label in train_dataset.images]))\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 32, sampler = train_sampler)\n",
    "val_loader = DataLoader(train_dataset, batch_size = 32, sampler = val_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.bencmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(nn.functional.softplus(x))\n",
    "\n",
    "class GIGAJINI(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GIGAJINI, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride =1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride= 2)\n",
    "        )\n",
    "\n",
    "        self.layer6 = torch.nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer7 = torch.nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            Mish(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.fc =torch.nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 2, bias = True),            \n",
    "            Mish()\n",
    "        )        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GIGAJINI().to(device)\n",
    "learning_rate = 1e-4\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "class_weight = torch.tensor([0.1, 0.9])\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weight).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs, learning_rate, patience):\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    epochs_without_importvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        avg_loss = 0\n",
    "\n",
    "        for X, Y in train_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "        avg_loss /= len(train_loader)\n",
    "\n",
    "        val_loss = evaluate(model, val_loader) \n",
    "\n",
    "        print(f'Epoch : {epoch + 1}, Train Loss : {avg_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "            print('Model Saved')\n",
    "            epochs_without_importvement = 0\n",
    "\n",
    "        else:\n",
    "            epochs_without_importvement += 1\n",
    "\n",
    "        if epochs_without_importvement >= patience:\n",
    "            print(f'Early stopping: No improvement in validation loss for {patience} epochs.')\n",
    "            break\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Train Loss : 0.1877, Validation Loss: 0.6210\n",
      "Model Saved\n",
      "Epoch : 2, Train Loss : 0.0703, Validation Loss: 0.4682\n",
      "Model Saved\n",
      "Epoch : 3, Train Loss : 0.0715, Validation Loss: 0.2317\n",
      "Model Saved\n",
      "Epoch : 4, Train Loss : 0.0564, Validation Loss: 0.1107\n",
      "Model Saved\n",
      "Epoch : 5, Train Loss : 0.0690, Validation Loss: 0.0594\n",
      "Model Saved\n",
      "Epoch : 6, Train Loss : 0.0382, Validation Loss: 0.0518\n",
      "Model Saved\n",
      "Epoch : 7, Train Loss : 0.0359, Validation Loss: 0.0674\n",
      "Epoch : 8, Train Loss : 0.0300, Validation Loss: 0.0645\n",
      "Epoch : 9, Train Loss : 0.0339, Validation Loss: 0.0365\n",
      "Model Saved\n",
      "Epoch : 10, Train Loss : 0.0225, Validation Loss: 0.0527\n",
      "Epoch : 11, Train Loss : 0.0150, Validation Loss: 0.0241\n",
      "Model Saved\n",
      "Epoch : 12, Train Loss : 0.0091, Validation Loss: 0.0314\n",
      "Epoch : 13, Train Loss : 0.0123, Validation Loss: 0.2782\n",
      "Epoch : 14, Train Loss : 0.0144, Validation Loss: 0.0255\n",
      "Epoch : 15, Train Loss : 0.0086, Validation Loss: 0.5634\n",
      "Epoch : 16, Train Loss : 0.0030, Validation Loss: 0.0123\n",
      "Model Saved\n",
      "Epoch : 17, Train Loss : 0.0022, Validation Loss: 0.0094\n",
      "Model Saved\n",
      "Epoch : 18, Train Loss : 0.0048, Validation Loss: 0.0063\n",
      "Model Saved\n",
      "Epoch : 19, Train Loss : 0.0023, Validation Loss: 0.0144\n",
      "Epoch : 20, Train Loss : 0.0026, Validation Loss: 0.0269\n",
      "Epoch : 21, Train Loss : 0.0011, Validation Loss: 0.0101\n",
      "Epoch : 22, Train Loss : 0.0017, Validation Loss: 0.0097\n",
      "Epoch : 23, Train Loss : 0.0005, Validation Loss: 0.0079\n",
      "Early stopping: No improvement in validation loss for 5 epochs.\n",
      "Test Loss: 0.0016, Accuracy: 100.00%\n",
      "F1 Score (Micro): 1.00000000\n",
      "F1 Score (Macro): 1.00000000\n",
      "F1 Score (Weighted): 1.00000000\n",
      "Precision (Micro): 1.00000000\n",
      "Precision (Macro): 1.00000000\n",
      "Precision (Weighted): 1.00000000\n",
      "Recall (Micro): 1.00000000\n",
      "Recall (Macro): 1.00000000\n",
      "Recall (Weighted): 1.00000000\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 0 20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patience = 5\n",
    "best_model = train(model, train_loader, val_loader, epochs, learning_rate, patience)\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        output = model(X)\n",
    "        test_loss += criterion(output, Y).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(Y.view_as(pred)).sum().item()\n",
    "\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(Y.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# F1 score 계산\n",
    "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1 Score (Micro): {f1_micro:.8f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.8f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.8f}\")\n",
    "\n",
    "# Precision 계산\n",
    "precision_micro = precision_score(all_labels, all_preds, average='micro')\n",
    "precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
    "precision_weighted = precision_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"Precision (Micro): {precision_micro:.8f}\")\n",
    "print(f\"Precision (Macro): {precision_macro:.8f}\")\n",
    "print(f\"Precision (Weighted): {precision_weighted:.8f}\")\n",
    "\n",
    "# Recall 계산\n",
    "recall_micro = recall_score(all_labels, all_preds, average='micro')\n",
    "recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
    "recall_weighted = recall_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"Recall (Micro): {recall_micro:.8f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.8f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.8f}\")\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# 분류 리포트 출력\n",
    "class_names = [str(num) for num in torch.arange(2).tolist()]\n",
    "classification_rep = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
